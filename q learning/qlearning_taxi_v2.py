# -*- coding: utf-8 -*-
"""qlearning-taxi-v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r7-3A9EFk1xMN77EepKXwzDTS2kQOpsM
"""

!pip install gym

import gym
import numpy as np
import random

from IPython.display import clear_output
import time

env = gym.make('Taxi-v2')

states=env.observation_space.n
actions=env.action_space.n
print(states,actions)

qtable=np.zeros((states,actions))
qtable.shape

total_episodes=100000
lr=0.9
max_steps=400
gamma=0.9

epsilon=1
max_epsilon=1
min_epsilon=0.01
decay_rate=0.001

rewards=[]
for episode in range(total_episodes):
  step=0
  total_reward=0
  state=env.reset()
  for step in range(max_steps):
    exp_exp_tradeoff=random.uniform(0,1)
    if exp_exp_tradeoff>epsilon:
      action=np.argmax(qtable[state,:])
    else:
      action=env.action_space.sample()
    new_state,reward,done,info=env.step(action)
    qtable[state,action]+=lr*(reward+gamma*(np.max(qtable[new_state,:]))-qtable[state,action])
    total_reward+=reward
    state=new_state
    if done:
      break
  rewards.append(total_reward)
  epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) 
avg_reward=np.sum(rewards)/total_episodes
print(avg_reward)
env.close()

for episode in range(2):
  total_reward=0
  state=env.reset()
  print("*********************************** Episode : "+str(episode+1))
  time.sleep(1)
  env.render()
  time.sleep(0.5)
  clear_output()
  for step in range(400):
    action=np.argmax(qtable[state,:])
    new_state,reward,done,info=env.step(action)
    total_reward+=reward
    state=new_state
    env.render()
    time.sleep(1)
    clear_output()
    if done:
      break
  print("total reward : "+str(total_reward))
  time.sleep(1.5)
  clear_output()

